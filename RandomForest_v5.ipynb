{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.utils import shuffle\n",
    "#from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../wer_manASR_feat_v30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all +-inf with NaNs\n",
    "df = df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return list of columns that have only NaN values\n",
    "df.columns[df.isnull().all()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the NaNs columns\n",
    "df.drop(['diff_norm_pos_SPACE','diff_norm_sub_coord_ratio','diff_norm_tag_\"\"', 'diff_norm_tag_#', 'diff_norm_tag_$', 'diff_norm_tag_-PRB-', 'diff_norm_tag_BES', 'diff_norm_tag_GW', 'diff_norm_tag_HVS', 'diff_norm_tag_SP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute NaN for feature columns and store them in the new dataframe\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "clean_df = pd.DataFrame(imp.fit_transform(df.iloc[:, 22:982]), columns = list(df)[22:982])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append new dataframe with selected columns\n",
    "clean_df = clean_df.join([df.iloc[:,-5], df.iloc[:,-4], df.iloc[:,-3], df.iloc[:,-2], df.iloc[:,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of subject names\n",
    "subj_names = df.iloc[:, -1].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select feature names\n",
    "man_feat = list(df)[22:502]\n",
    "asr_feat = list(df)[502:982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle rows for better classification\n",
    "clean_df = shuffle(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick random forest for classifier\n",
    "clf = RandomForestClassifier(n_estimators = 10, max_depth = 20, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOCV function\n",
    "def transcript_loocv(subject_names, classifier_name, clf, df_clean, featureset):\n",
    "    warnings.simplefilter('error')\n",
    "    accuracy_fold = []\n",
    "    accuracy_fold1 = []\n",
    "    precision_fold = []\n",
    "    recall_fold = []\n",
    "    spec_fold = []\n",
    "    f1_arr = []\n",
    "    report = []\n",
    "    for name in subject_names:\n",
    "        df_data = df_clean.copy()\n",
    "        df_data = df_data[df_data.firstname.isin(subject_names)]\n",
    "        ind_train = [~df_data['firstname'].isin([name])]\n",
    "        ind_test = [df_data['firstname'].isin([name])]\n",
    "        df_data = df_data.sort_values('age_at_record')\n",
    "        #for every train-test split, obtain means only from training HC group (so that model is completely agnostic to labels)\n",
    "        #X = df_data.iloc[:,0:len(features)].values\n",
    "        X = df_data[featureset].values\n",
    "\n",
    "        y_label = df_data['group_label_id'].values\n",
    "        years = df_data['age_at_record'].values\n",
    "        years_diag = df_data['year_diag'].values\n",
    "        sub_id = df_data['subject_id'].values\n",
    "        y_label[y_label==2]=0\n",
    "        #print('this is weird ==2 y-lable', y_label)\n",
    "\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        sel = VarianceThreshold(threshold=(.99 * (1 - .99)))\n",
    "        X = sel.fit_transform(X)\n",
    "        #print(name)\n",
    "        ind_train = [~df_data['firstname'].isin([name])]\n",
    "        ind_test = [df_data['firstname'].isin([name])]\n",
    "        #print(ind_test)\n",
    "\n",
    "        X_train = X[tuple(ind_train)]\n",
    "        X_test = X[tuple(ind_test)]\n",
    "        #print(X_test)\n",
    "        y_train = y_label[tuple(ind_train)]\n",
    "        #print('y-train', y_train)\n",
    "        y_test = y_label[tuple(ind_test)]\n",
    "        #print('y-test', y_test)\n",
    "        X_train,y_train = SMOTE(random_state=1,k_neighbors=3).fit_sample(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        \n",
    "        #print(\"y_test\", y_test)\n",
    "        #print(\"pred\", prediction)\n",
    "        \n",
    "        sensitivity = recall_score(y_pred = prediction, y_true = y_test, average='macro')\n",
    "        specificity = specificity_score(y_true = y_test, y_pred = prediction, average='macro')\n",
    "        precision = precision_score(y_pred = prediction, y_true = y_test, average='macro')\n",
    "        f1 = f1_score(y_pred = prediction, y_true = y_test, average='macro')  \n",
    "        \n",
    "        accuracy_fold.append(accuracy_score(y_true = y_test, y_pred = prediction))\n",
    "        precision_fold.append(precision)\n",
    "        recall_fold.append(sensitivity)\n",
    "        f1_arr.append(f1)\n",
    "        spec_fold.append(specificity)\n",
    "        \n",
    "    return np.mean(accuracy_fold),np.mean(precision_fold),np.mean(recall_fold),np.mean(f1_arr),np.mean(spec_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run LOOCV on manual transcript features\n",
    "manual_tr_performance = []\n",
    "for i in range(5):\n",
    "    manual_tr_performance.append([transcript_loocv(subj_names, 'random_forest', clf, clean_df, man_feat)])\n",
    "avg_manual_tr_performance = np.mean(manual_tr_performance, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_manual_tr_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run LOOCV on asr transcript features\n",
    "asr_tr_performance = []\n",
    "for i in range(5):\n",
    "    asr_tr_performance.append([transcript_loocv(subj_names, 'random_forest', clf, clean_df, asr_feat)])\n",
    "avg_asr_tr_performance = np.mean(asr_tr_performance, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_asr_tr_performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
